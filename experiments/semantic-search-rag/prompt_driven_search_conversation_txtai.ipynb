{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "id": "OUc9gqTyAYnm"
      },
      "outputs": [],
      "source": [
        "from txtai.embeddings import Embeddings\n",
        "from txtai.pipeline import Extractor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define constants\n",
        "EMBEDDINGS_PATH = './text_embeddings'\n",
        "LLM_MODEL = 'google/flan-t5-base'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load the embeddings\n",
        "embeddings = Embeddings()\n",
        "embeddings.load(EMBEDDINGS_PATH)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create extractor instance\n",
        "extractor = Extractor(embeddings, LLM_MODEL)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5O1WBJ8153Mo",
        "outputId": "ddf09da2-7d4c-4fd3-b0da-df5631bacd13"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1103 > 512). Running this sequence through the model will result in indexing errors\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Q: Some news about the Apple company\n",
            "A: Apple Inc chief Tim Cook met Indian Prime Minister Narendra Modi on Saturday, concluding a four-day trip to India that could set the stage for Apple s expansion plans in one of the world s fastest growing smartphone markets.\n"
          ]
        }
      ],
      "source": [
        "def prompt(question):\n",
        "  return f\"\"\"Generate a comprehensive and informative, yet concise answer of 250 words or less for the\n",
        "given question based solely on the provided context. You must only use information from the provided context.\n",
        "You should use bullet points in your answer for readability. Put citations where they apply\n",
        "rather than putting them all at the end.\n",
        "If there is nothing in the context relevant to the question at hand, just say \"Hmm,\n",
        "I'm not sure.\" Don't try to make up an answer.\n",
        "Question: {question}\n",
        "Context: \"\"\"\n",
        "\n",
        "def search(query, question=None):\n",
        "  # Default question to query if empty\n",
        "  if not question:\n",
        "    question = query\n",
        "\n",
        "  return extractor([(\"answer\", query, prompt(question), False)])[0][1]\n",
        "\n",
        "question = \"Some news about the Apple company\"\n",
        "answer = search(question)\n",
        "print(f\"Q: {question}\", f\"A: {answer}\", sep=\"\\n\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
